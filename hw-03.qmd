---
title: "HW 03"
author: "Brooke Pacheco"
format:
  html:
    embed-resources: true
toc: true
---
## 0 - Setup

```{r setup}
# load packages
library(tidyverse)
library(glue)
library(here)
library(countdown)
library(ggthemes)
library(gt)
library(openintro)
library(ggrepel)
library(patchwork)

# set theme for ggplot2
ggplot2::theme_set(ggplot2::theme_minimal(base_size = 11))

# set width of code output
options(width = 65)

# set figure parameters for knitr
knitr::opts_chunk$set(
  fig.width = 7,        # 7" width
  fig.asp = 0.618,      # the golden ratio
  fig.retina = 3,       # dpi multiplier for displaying HTML output on retina
  fig.align = "center", # center align figures
  dpi = 300             # higher dpi, sharper image
)

if (!require("pacman")) 
  install.packages("pacman")

# use this line for installing/loading
pacman::p_load(tidyverse,
               glue,
               scales,
               ggthemes) 

devtools::install_github("tidyverse/dsbox")

```

## 1 - Du Bois challenge.

```{r}
#| label: Recreation of Du Bois Plot

# Read in data from income file
income <- read_csv(here("data" ,"income.csv"))

income <- income |>
  pivot_longer(
    cols = c(Rent, Food, Clothes, Tax, Other),
    names_to = "Type",
    values_to = "Total_Amount"
  ) |>
  mutate(
    Type = factor(Type, levels = c("Other", "Tax", "Clothes", "Food", "Rent")),
    Class = factor(Class, levels = c("$1000 AND OVER", "$750-1000", "$500-750", "$400-500", "$300-400", "$200-300", "$100-200")),
    Percent = round((Total_Amount / Average_Income) * 100)
  ) |>
  glimpse()

# Create the histogram plot
ggplot(income, aes(x = Total_Amount, y = Class, fill = Type)) +
  geom_col(position = "stack") +
  scale_fill_manual(
    values = c("Rent" = "#000000", "Food" = "#C3B1E1", "Clothes" = "#F89880", "Tax" = "#B7C9E2", "Other" = "#E6ECF5")) +
  geom_text(
    aes(label = percent(Percent)),
    position = position_stack(vjust = 0.5),
    color = "black",
    size = 3
  ) +
  labs(
    title = "Du Bois Plot Recreation",
    x = "Amount Spent",
    y = "Income Class"
  ) +
  theme_minimal(base_size = 11)

```
### Sources
hex color values:
https://htmlcolorcodes.com/colors/

## 2 - COVID survey - interpret

#### Example 1:
For the response variable "Getting the vaccine will make me feel safer at work", nurses had an average response close to 1, with a relatively narrow confidence interval. This indicates that most nurses agreed with the statement, and the estimate is fairly precise. Medical professionals, on the other hand, had a mean closer to 2 with a wider confidence interval. This suggests that while medical professionals also tended to agree, they were on average slightly less certain than nurses. Additionally, the wider confidence interval for medical professionals indicates greater variability in their responses and less precision in the estimate compared to the nurses. The responses did surprise me. I initially thought that medical professionals might be more confident than nurses because they typically have more training. However, on second thought, the confidence interval for the medical professionals group is much wider, suggesting greater variability and less precision in their responses.

#### Example 2:
For the response variable "I am concerned about the safety and side effects of the vaccine", the Non-Hispanic/Non-Latino group has a slightly higher mean (around 3.5) with a relatively wide confidence interval. The Hispanic/Latino group has a mean closer to 3, also with a wide confidence interval. Notably, the confidence interval for the Non-Hispanic/Non-Latino group is slightly wider than that of the Hispanic/Latino group. These results suggest that, on average, both groups are neutral in their concern about the vaccine's safety and side effects. However, the wide confidence intervals indicate a fair amount of uncertainty around these means, making the estimates less precise. Though the overlap between intervals suggests no statistically significant difference between the two groups. The results do not surprise me; regardless of ethnicity, I would expect both groups to have similar opinions.

#### Example 3:
For the response variable "I trust the information that I have received about the vaccines", the group that reported having received the COVID vaccine had a mean close to 1, with a narrow confidence interval. This indicates strong agreement with the statement and a high level of precision in the estimate. In contrast, the group that reported not having received the vaccine had a mean around 3, with a wide confidence interval. This suggests that those who were unvaccinated were generally neutral in their trust of vaccine information, and the wide confidence interval reflects greater uncertainty and less precision in this group's response. The results make sense; I would expect unvaccinated individuals to be less confident in the information compared to those who have received the vaccine.

## 3 - COVID survey - reconstruct

```{r}
#| label: Reconstruct COVID Survey 

# Read in data from COVID survey file and skip first row
covid_survey <- read_csv(here("data", "covid-survey.csv"), skip = 1)

# Print dimensions of data frame
dim(covid_survey)

# Data cleanup - eliminate any rows where all values aside from response_id are missing
cleaned_survey <- covid_survey |>
  filter(!if_all(-response_id, is.na))

# Print dimensions of cleaned data frame
dim(cleaned_survey)

# Relabel the survey response values
relabeled_survey <- cleaned_survey |>
  mutate(
    exp_already_vax = factor(case_match(exp_already_vax, 0 ~ "No", 1 ~ "Yes")),
    exp_flu_vax = factor(case_match(exp_flu_vax, 0 ~ "No", 1 ~ "Yes")),
    exp_profession = factor(case_match(exp_profession, 0 ~ "Medical", 1 ~ "Nursing")),
    exp_gender = factor(case_match(exp_gender, 0 ~ "Male", 1 ~ "Female", 3 ~ "Non-binary/Third gender", 4 ~ "Prefer not to say")),
    exp_race = factor(case_match(exp_race, 1 ~ "American Indian / Alaskan Native", 2 ~ "Asian", 3 ~ "Black / African American", 4 ~ "Native Hawaiian / Other Pacific Islander", 5 ~ "White")),
    exp_ethnicity = factor(case_match(exp_ethnicity, 1 ~ "Hispanic / Latino", 2 ~ "Non-Hispanic / Non-Latino")),
    exp_age_bin = factor(case_when(exp_age_bin == 0 ~ "<20", exp_age_bin == 20 ~ "21-25", exp_age_bin == 25 ~ "26-30", exp_age_bin == 30 ~ ">30", TRUE ~ as.character(exp_age_bin))
    )
  )

# Print dimensions of relabeled survey
dim(relabeled_survey)

# Calculate the 10th percentile, mean, and 90th percentile of each of the response variables for each level of each explanatory variable.
covid_survey_longer <- relabeled_survey |>
  # Takes all the columns starting with "exp_" and creates them into two columns: explanatory and explanatory_value.
  pivot_longer(
    cols = starts_with("exp_"),
    names_to = "explanatory",
    values_to = "explanatory_value"
  ) |>
  filter(!is.na(explanatory_value)) |>
  # Takes all the columns starting with "resp_" and creates them into two columns: response and response_value.
  pivot_longer(
    cols = starts_with("resp_"),
    names_to = "response",
    values_to = "response_value"
  )

# Print dimensions of data frame and confirm tribble table matches homework 
covid_survey_longer
dim(covid_survey_longer)

# Group data in covid_survey_longer
covid_survey_summary_stats_by_group <- covid_survey_longer |>
  group_by(explanatory, explanatory_value, response) |>
  summarise(
    mean = mean(response_value, na.rm = TRUE),
    low = quantile(response_value, 0.10, na.rm = TRUE),
    high = quantile(response_value, 0.90, na.rm = TRUE),
    .groups = "drop"
  )

# View the summary tibble
covid_survey_summary_stats_by_group

# Check dimensions
dim(covid_survey_summary_stats_by_group)

# Group data in covid_survey_longer only by response
covid_survey_summary_stats_all <- covid_survey_longer |>
  group_by(response) |>
  summarise(
    mean = mean(response_value, na.rm = TRUE),
    low  = quantile(response_value, 0.10, na.rm = TRUE),
    high = quantile(response_value, 0.90, na.rm = TRUE),
    .groups = "drop"
  ) |>
  mutate(
    explanatory = "All",
    explanatory_value = factor("")
  ) |>
  select(explanatory, explanatory_value, everything())

# View the result
covid_survey_summary_stats_all

# Check dimensions
dim(covid_survey_summary_stats_all)

# Bind both summary tables together
covid_survey_summary_stats <- bind_rows(
  covid_survey_summary_stats_all,
  covid_survey_summary_stats_by_group
)

# Check final dimensions 
dim(covid_survey_summary_stats)

# View final summary
covid_survey_summary_stats

ggplot(covid_survey_summary_stats, aes(x = mean, y = explanatory_value)) +
  geom_point(
    size = 0.5,
  ) +
  geom_errorbarh(
    aes(xmin = low, xmax = high),
    height = 0.5, 
    color = "black"
  ) +
  facet_grid(explanatory_value ~ response, scales = "free_y", space = "free_y") +
  labs(
    title = "TODO",
    x = "TODO",
    y = NULL
  ) + 
  theme_minimal(base_size = 11) +
  theme(
    strip.background = element_rect(fill = "grey90", color = NA)
  )
```

### Sources
To not select a column, used '-' directly from:
https://stackoverflow.com/questions/49582602/how-not-to-select-columns-using-select-dplyr-when-you-have-character-vector-of

Directly referenced to remove NA data before evaluating expression:
https://stat.ethz.ch/R-manual/R-devel/library/base/html/mean.html

Referenced for quantile function:
https://stat.ethz.ch/R-manual/R-devel/library/stats/html/quantile.html

Referenced for ticks at end of bars:
https://ggplot2.tidyverse.org/reference/geom_errorbarh.html

## 4 - COVID survey - re-reconstruct

## 5 - COVID survey - another view
